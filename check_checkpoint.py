#!/usr/bin/env python3
"""
Ê£ÄÊü•checkpointÊñá‰ª∂ÁöÑÂÜÖÂÆπÂíåÁªìÊûÑ
"""

import torch
import argparse

def check_checkpoint(ckpt_path):
    """Ê£ÄÊü•checkpointÊñá‰ª∂ÁöÑËØ¶ÁªÜ‰ø°ÊÅØ"""
    
    print(f"üîç Checking checkpoint: {ckpt_path}")
    print("=" * 60)
    
    try:
        # Âä†ËΩΩcheckpoint
        ckpt = torch.load(ckpt_path, map_location='cpu')
        
        print(f"üìÅ Checkpoint type: {type(ckpt)}")
        
        if isinstance(ckpt, dict):
            print(f"üìã Checkpoint keys: {list(ckpt.keys())}")
            
            # Ê£ÄÊü•ÊØè‰∏™ÈîÆÁöÑÂÜÖÂÆπ
            for key, value in ckpt.items():
                if isinstance(value, dict):
                    print(f"\nüîë Key '{key}' contains {len(value)} items:")
                    # ÊòæÁ§∫ÂâçÂá†‰∏™ÂèÇÊï∞ÂêçÁß∞
                    param_names = list(value.keys())[:10]
                    for name in param_names:
                        if hasattr(value[name], 'shape'):
                            print(f"  - {name}: {value[name].shape}")
                        else:
                            print(f"  - {name}: {type(value[name])}")
                    if len(value) > 10:
                        print(f"  ... and {len(value) - 10} more parameters")
                        
                elif hasattr(value, 'shape'):
                    print(f"\nüîë Key '{key}': tensor with shape {value.shape}")
                else:
                    print(f"\nüîë Key '{key}': {type(value)} - {value}")
        
        else:
            # Â¶ÇÊûúÁõ¥Êé•ÊòØstate_dict
            print(f"üìã Direct state_dict with {len(ckpt)} parameters")
            param_names = list(ckpt.keys())[:20]
            for name in param_names:
                if hasattr(ckpt[name], 'shape'):
                    print(f"  - {name}: {ckpt[name].shape}")
            if len(ckpt) > 20:
                print(f"  ... and {len(ckpt) - 20} more parameters")
        
        # Ê£ÄÊü•Ê®°ÂûãÂ±ÇÊï∞
        if isinstance(ckpt, dict):
            state_dict = None
            if 'model_state_dict' in ckpt:
                state_dict = ckpt['model_state_dict']
            elif 'state_dict' in ckpt:
                state_dict = ckpt['state_dict']
            else:
                state_dict = ckpt
        else:
            state_dict = ckpt
            
        if state_dict:
            # Êü•Êâætemporal_decoder_blocksÁöÑÊúÄÂ§ßÁ¥¢Âºï
            max_layer = -1
            for key in state_dict.keys():
                if 'temporal_decoder_blocks.' in key:
                    try:
                        layer_idx = int(key.split('temporal_decoder_blocks.')[1].split('.')[0])
                        max_layer = max(max_layer, layer_idx)
                    except:
                        pass
            
            if max_layer >= 0:
                print(f"\nüèóÔ∏è Model architecture info:")
                print(f"  - Maximum layer index: {max_layer}")
                print(f"  - Total layers: {max_layer + 1}")
            
            # Ê£ÄÊü•condition encoder
            has_condition = any('condition_encoder' in key for key in state_dict.keys())
            print(f"  - Has condition encoder: {has_condition}")
            
            if has_condition:
                condition_keys = [key for key in state_dict.keys() if 'condition_encoder' in key]
                print(f"  - Condition encoder parameters: {len(condition_keys)}")
                for key in condition_keys[:5]:
                    print(f"    - {key}: {state_dict[key].shape}")
        
        print("\n‚úÖ Checkpoint analysis completed!")
        
    except Exception as e:
        print(f"‚ùå Error loading checkpoint: {e}")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--ckpt', required=True, help='Path to checkpoint file')
    args = parser.parse_args()
    
    check_checkpoint(args.ckpt)

if __name__ == '__main__':
    main()
